# -*- coding: utf-8 -*-
"""rrControls

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-zxywP_lvB_qhVKOn9WzE5B22PND8dBD
"""

import pandas as pd
import numpy as np
import torch as torch
import os, sys
import math


import matplotlib.pyplot as plt
from sklearn.linear_model import Lasso
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV, KFold
from sklearn import preprocessing
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import LabelEncoder
from sklearn import linear_model
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_predict
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error
from scipy.stats import pearsonr
from sklearn import linear_model
import seaborn as sb

import random

data = pd.read_csv("BLB_fullset.csv")
data.head()

"""ridge regression control within each year on increasingly unseen data"""

trait =["pheno.yd18","pheno.yd19","pheno.sw18","pheno.sw19","pheno.dm18","pheno.dm19"]

for name in trait:
  data = pd.read_csv("BLB_fullset.csv")

  X = data.drop(columns=[col for col in data.columns if "pheno" in col or col in ["Unnamed: 0", "Row.names"]])
  y = data[name]
  fullset = pd.concat([X,y],axis=1)
  fullset.dropna(subset=[name], inplace=True) # Drop rows with NaN in the target column
  data = fullset.dropna()
  X = fullset.drop([name],axis=1)
  y = fullset[name]

  xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size=0.33, shuffle=True)
  xTest, xValid, yTest, yValid = train_test_split(xTest, yTest, test_size=0.5, shuffle=True)

  '''determine best alpha value for RR'''

  xTrain, xValid, yTrain, yValid = train_test_split(xTrain, yTrain, test_size=0.33, shuffle=True)

  alphaValues = {}
  params =[0.01,0.1,1,10,100,1000]
  for values in params:
    LR = linear_model.Ridge(values)
    LR.fit(xTrain, yTrain)
    yPred = LR.predict(xValid)
    yValid = np.array(yValid)
    alphaValues[values] = np.corrcoef(yPred, yValid)[0,1]
    alphaVal = max(alphaValues, key=alphaValues.get)

  print(alphaVal)
  testProp = [slice(0, int(round(X.shape[0]*0.6,0))),
              slice(0, int(round(X.shape[0]*0.7,0))),
              slice(0, int(round(X.shape[0]*0.8,0))),
              slice(0, int(round(X.shape[0]*0.9,0))),
              slice(0, int(round(X.shape[0]*0.99,0))),
              slice(-int(round(X.shape[0]*0.9,)),None),
              slice(-int(round(X.shape[0]*0.8,)),None),
              slice(-int(round(X.shape[0]*0.7,)),None),
              slice(-int(round(X.shape[0]*0.6,)),None),
              slice(-int(round(X.shape[0]*0.5,)),None),
              slice(-int(round(X.shape[0]*0.4,)),None)]

  correlation_scores = []
  rmse_scores = []
  for x in testProp:

    trainingSet = fullset.iloc[0:int(round(X.shape[0]*0.6,0)),]
    testSet =fullset.iloc[x,]

    x_train = trainingSet.drop([name],axis=1)
    print(x_train.shape[0])
    y_train = trainingSet[name]
    x_test = testSet.drop([name],axis=1)
    print(x_test.shape[0])
    y_test = testSet[name]

    # Fit the model
    RR = linear_model.Ridge(alphaVal)
    RR.fit(x_train, y_train)

    # Make predictions
    y_pred = RR.predict(x_test)

    # Compute RMSE
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    rmse_scores.append(rmse)

    # Compute Pearson correlation
    corr, _ = pearsonr(y_test, y_pred)
    correlation_scores.append(corr)

  correlation_df = pd.DataFrame(correlation_scores).transpose()
  correlation_df = correlation_df.rename(columns={0: '1', 1: '0.9', 2: '0.8', 3: '0.7',4:'.6',5:'.5',6:'0.4',7:'0.3',8:'0.2',9:'0.1',10:'0.0'})

  correlation_df.to_csv(f"{name}_results.csv")

"""ridge regression control testing among years for each trait"""

yield18 = data[["pheno.yd18","pheno.taxa"]]
yield19 = data[["pheno.yd19","pheno.taxa"]]

weight18 = data[["pheno.sw18","pheno.taxa"]]
weight19 = data[["pheno.sw19","pheno.taxa"]]

maturity18 = data[["pheno.dm18","pheno.taxa"]]
maturity19 = data[["pheno.dm19","pheno.taxa"]]

geno = data.filter(regex='geno')
entries = data[['pheno.taxa']]
entries.columns = ['pheno.taxa']
geno = pd.concat([entries,geno],axis=1)

train = pd.merge(maturity18, geno, on="pheno.taxa")
test = pd.merge(maturity19, geno, on="pheno.taxa")
train = train.dropna()
test = test.dropna()

xTrain = train.drop(["pheno.dm18","pheno.taxa",0],axis=1)
yTrain = train["pheno.dm18"]
xTest = test.drop(["pheno.dm19","pheno.taxa",0],axis=1)
yTest = test['pheno.dm19']

xTrain, xValid, yTrain, yValid = train_test_split(xTrain, yTrain, test_size=0.33, shuffle=True)

alphaValues = {}
params =[0.01,0.1,1,10,100,1000]
for values in params:
  LR = linear_model.Ridge(values)
  LR.fit(xTrain, yTrain)
  yPred = LR.predict(xValid)
  yValid = np.array(yValid)
  alphaValues[values] = np.corrcoef(yPred, yValid)[0,1]
  alphaVal = max(alphaValues, key=alphaValues.get)

RR = linear_model.Ridge(alphaVal)
RR.fit(xTrain, yTrain)

# Make predictions
y_pred = RR.predict(xTest)
y_pred = pd.Series(y_pred, index=xTest.index)

# Compute Pearson correlation
corr, _ = pearsonr(yTest, y_pred)

corr

"""ridge regression control testing among locations""

traits = ["SW","SY","DM","DF"]

for trait in traits:
  data= pd.read_csv(f"fullDataset{trait}_Updated.csv")

  locations = data["loc"].unique()
  locAccs = []


  for loc in locations:
    test = data[data["loc"] == loc]
    train = data[data["loc"] != loc]
    xTrain = train.drop(["Unnamed: 0","x","taxa","loc","pheno"],axis=1)
    yTrain = train["pheno"]
    xTest = test.drop(["Unnamed: 0","x","taxa","loc","pheno"],axis=1)
    yTest = test["pheno"]

    xTrain, xValid, yTrain, yValid = train_test_split(xTrain, yTrain, test_size=0.33, shuffle=True)

    alphaValues = {}
    params =[0.01,0.1,1,10,100,1000]
    for values in params:
      LR = linear_model.Ridge(values)
      LR.fit(xTrain, yTrain)
      yPred = LR.predict(xValid)
      yValid = np.array(yValid)
      alphaValues[values] = np.corrcoef(yPred, yValid)[0,1]
      alphaVal = max(alphaValues, key=alphaValues.get)

    # Fit the model
    RR = linear_model.Ridge(alphaVal)
    RR.fit(xTrain, yTrain)

    # Make predictions
    y_pred = RR.predict(xTest)
    y_pred = pd.Series(y_pred, index=xTest.index)

    # Compute Pearson correlation
    corr, _ = pearsonr(yTest, y_pred)
    locAccs.append(corr)

  locations = pd.DataFrame(locations)
  resutls = pd.concat([locations,pd.Series(locAccs)],axis=1)

  resutls.to_csv(f"loc_{trait}.csv")
